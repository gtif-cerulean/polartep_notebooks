{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "6cf62c5a",
            "metadata": {
                "image": "sice.png"
            },
            "source": [
                "# Sentinel-3 Snow and ICE products (SICE)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "4c0a3ab2-dd20-4e11-bd8a-1ae66d04222f",
            "metadata": {
                "collapsed": true,
                "jupyter": {
                    "outputs_hidden": true
                },
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Defaulting to user installation because normal site-packages is not writeable\n",
                        "Requirement already satisfied: sentinelhub in ./.local/lib/python3.9/site-packages (3.8.4)\n",
                        "Requirement already satisfied: aenum>=2.1.4 in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from sentinelhub) (3.1.11)\n",
                        "Requirement already satisfied: requests-oauthlib>=1.0.0 in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from sentinelhub) (1.3.1)\n",
                        "Requirement already satisfied: numpy in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from sentinelhub) (1.23.5)\n",
                        "Requirement already satisfied: typing-extensions in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from sentinelhub) (4.4.0)\n",
                        "Requirement already satisfied: tifffile>=2020.9.30 in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from sentinelhub) (2022.10.10)\n",
                        "Requirement already satisfied: shapely in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from sentinelhub) (1.8.5.post1)\n",
                        "Requirement already satisfied: oauthlib in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from sentinelhub) (3.2.2)\n",
                        "Requirement already satisfied: tqdm in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from sentinelhub) (4.64.1)\n",
                        "Requirement already satisfied: requests>=2.27.0 in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from sentinelhub) (2.28.1)\n",
                        "Requirement already satisfied: python-dateutil in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from sentinelhub) (2.8.2)\n",
                        "Requirement already satisfied: utm in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from sentinelhub) (0.7.0)\n",
                        "Requirement already satisfied: dataclasses-json in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from sentinelhub) (0.5.7)\n",
                        "Requirement already satisfied: pillow>=9.2.0 in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from sentinelhub) (9.2.0)\n",
                        "Requirement already satisfied: click in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from sentinelhub) (8.0.4)\n",
                        "Requirement already satisfied: pyproj>=2.2.0 in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from sentinelhub) (3.4.0)\n",
                        "Requirement already satisfied: certifi in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from pyproj>=2.2.0->sentinelhub) (2022.9.24)\n",
                        "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from requests>=2.27.0->sentinelhub) (1.26.13)\n",
                        "Requirement already satisfied: charset-normalizer<3,>=2 in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from requests>=2.27.0->sentinelhub) (2.1.1)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from requests>=2.27.0->sentinelhub) (3.4)\n",
                        "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from dataclasses-json->sentinelhub) (1.5.1)\n",
                        "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from dataclasses-json->sentinelhub) (3.19.0)\n",
                        "Requirement already satisfied: typing-inspect>=0.4.0 in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from dataclasses-json->sentinelhub) (0.8.0)\n",
                        "Requirement already satisfied: six>=1.5 in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from python-dateutil->sentinelhub) (1.16.0)\n",
                        "Requirement already satisfied: packaging>=17.0 in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->sentinelhub) (21.3)\n",
                        "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from typing-inspect>=0.4.0->dataclasses-json->sentinelhub) (0.4.3)\n",
                        "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/conda/eurodatacube/509ef1ea91778cd89e0732da937c672a0e4c27fd9e360fadaa9831b15c3fb15c-20221207-163604-486302-65-edc-2022.10-14/lib/python3.9/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses-json->sentinelhub) (3.0.9)\n"
                    ]
                }
            ],
            "source": [
                "#%run ./prepare-sice-environment.ipynb\n",
                "! pip install --upgrade sentinelhub "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "3a652d84-56a8-45bb-83ee-816c76a2b8e0",
            "metadata": {
                "papermill": {
                    "duration": 1.161156,
                    "end_time": "2021-05-11T14:54:55.668650",
                    "exception": false,
                    "start_time": "2021-05-11T14:54:54.507494",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "\n",
                "## Credentials needs to be filled in the code in order to make it work!\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import os\n",
                "import logging\n",
                "import subprocess\n",
                "from botocore.client import Config as botoConfig\n",
                "from botocore.exceptions import ClientError\n",
                "from oauthlib.oauth2 import BackendApplicationClient\n",
                "from requests_oauthlib import OAuth2Session\n",
                "import boto3\n",
                "import glob\n",
                "import time\n",
                "import rasterio\n",
                "from shapely import geometry\n",
                "from osgeo import ogr\n",
                "\n",
                "logging = logging.getLogger(__name__)\n",
                "\n",
                "def plot_image(image, factor=1.0, clip_range=None, **kwargs):\n",
                "    \"\"\"\n",
                "    Utility function for plotting RGB images.\n",
                "    \"\"\"\n",
                "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15))\n",
                "    if clip_range is not None:\n",
                "        ax.imshow(np.clip(image * factor, *clip_range), **kwargs)\n",
                "    else:\n",
                "        ax.imshow(image * factor, **kwargs)\n",
                "    ax.set_xticks([])\n",
                "    ax.set_yticks([])\n",
                "    \n",
                "    \n",
                "def merge_tiffs(input_filename_list, merged_filename, *, overwrite=False, delete_input=False):\n",
                "    \"\"\"Performs gdal_merge on a set of given geotiff images\n",
                "\n",
                "    :param input_filename_list: A list of input tiff image filenames\n",
                "    :param merged_filename: Filename of merged tiff image\n",
                "    :param overwrite: If True overwrite the output (merged) file if it exists\n",
                "    :param delete_input: If True input images will be deleted at the end\n",
                "    \"\"\"\n",
                "    if os.path.exists(merged_filename):\n",
                "        if overwrite:\n",
                "            os.remove(merged_filename)\n",
                "        else:\n",
                "            raise OSError(f\"{merged_filename} exists!\")\n",
                "\n",
                "    logging.info(\"merging %d tiffs to %s\", len(input_filename_list), merged_filename)\n",
                "    subprocess.check_call(\n",
                "        [\"gdal_merge.py\", \"-co\", \"BIGTIFF=YES\", \"-co\", \"compress=LZW\", \"-ot\", \"Float32\" , \"-init\", \"-9999\" , \"-n\", \"-9999\", \"-a_nodata\", \"-9999\", \"-o\", merged_filename, *input_filename_list]\n",
                "    )\n",
                "    logging.info(\"merging done\")\n",
                "\n",
                "    if delete_input:\n",
                "        logging.info(\"deleting input files\")\n",
                "        for filename in input_filename_list:\n",
                "            if os.path.isfile(filename):\n",
                "                os.remove(filename)\n",
                "                \n",
                "def deleteProcessingData(dir):\n",
                "    logging.info(f'Deleting files from {dir}')\n",
                "    for file in glob.glob(f'{dir}/*_tmp.tif'):\n",
                "        logging.info(f'Deleting file {file}')\n",
                "        os.remove(file)\n",
                "\n",
                "def importToBucket(awsConfig, resultsFolder, processBands=False):\n",
                "    \n",
                "    try:\n",
                "        s3_client = boto3.resource('s3',\n",
                "                                   endpoint_url=awsConfig['s3Url'],\n",
                "                                   use_ssl=False,\n",
                "                                   aws_access_key_id=awsConfig['s3AccessKey'],\n",
                "                                   aws_secret_access_key=awsConfig['s3SecrestKey'],\n",
                "                                   config=botoConfig(\n",
                "                                       signature_version='s3',\n",
                "                                       connect_timeout=60,\n",
                "                                       read_timeout=60,\n",
                "                                   ))\n",
                "\n",
                "        bucket = s3_client.Bucket(awsConfig['bucketName'])\n",
                "    except Exception as e:\n",
                "        logging.error(e)\n",
                "        raise Exception('Invalid bucket parameters') \n",
                "    \n",
                "    coverGeometry = ''\n",
                "    \n",
                "    # get tif files to upload\n",
                "    filenamesList = glob.glob(f'{resultsFolder}/*.tif')\n",
                "    try:\n",
                "        for file in filenamesList:\n",
                "            destFile = file.replace(resultsFolder, awsConfig['folder'])\n",
                "            if processBands:\n",
                "                tmpFile = file.replace(\".tif\", \"_tmp.tif\")\n",
                "                cmd = \"gdal_translate -b 1 -of COG -a_nodata -9999 -co COMPRESS=DEFLATE -co BLOCKSIZE=1024 -co RESAMPLING=AVERAGE -co OVERVIEWS=IGNORE_EXISTING {0} {1}\".format(file, tmpFile)\n",
                "                logging.info(cmd)\n",
                "                os.system(cmd)\n",
                "                file = tmpFile\n",
                "                \n",
                "            if not coverGeometry:\n",
                "                coverGeometry = getMbrWithIntermediate(file)\n",
                "            \n",
                "            logging.info(f'Uploading {file} to {destFile}')\n",
                "            response = bucket.upload_file(file, destFile)\n",
                "        deleteProcessingData(resultsFolder)\n",
                "    except Exception as e:\n",
                "        logging.error(e)\n",
                "        raise Exception(f'Failed to upload file: {destFile}') \n",
                "        \n",
                "    return coverGeometry\n",
                "\n",
                "def addIntermediateY(x, y, diff, numPoints):\n",
                "    coords = []\n",
                "    coords.append([x, y])  \n",
                "    for i in range(numPoints):\n",
                "        coords.append([x, y + i / numPoints * diff])\n",
                "    return coords\n",
                "\n",
                "def addIntermediateX(x, y, diff, numPoints):\n",
                "    coords = []\n",
                "    coords.append([x, y])  \n",
                "    for i in range(numPoints):\n",
                "        coords.append([x + i / numPoints * diff, y])\n",
                "    return coords\n",
                "\n",
                "def getMbrWithIntermediate(file):\n",
                "    dataset = rasterio.open(file)\n",
                "    bounds = dataset.bounds\n",
                "    poly = getPolygonFromMbr(bounds.left, bounds.bottom, bounds.right, bounds.top, 20)\n",
                "    p = geometry.mapping(poly)\n",
                "    p['properties'] = {'name': 'urn:ogc:def:crs:EPSG::4326'}\n",
                "    return p         \n",
                "        \n",
                "def getPolygonFromMbr(xMin, yMin, xMax, yMax, numPoints):\n",
                "    coords = []\n",
                "    xDiff = xMax - xMin\n",
                "    yDiff = yMax - yMin\n",
                "    \n",
                "    coords.extend(addIntermediateY(xMin, yMin, yDiff, numPoints))\n",
                "    coords.extend(addIntermediateX(xMin, yMax, xDiff, numPoints))\n",
                "    coords.extend(addIntermediateY(xMax, yMax, -yDiff, numPoints))\n",
                "    coords.extend(addIntermediateX(xMax, yMin, -xDiff, numPoints))\n",
                "    poly = geometry.Polygon(coords)\n",
                "    return poly        \n",
                "        \n",
                "def deleteTile(s3folder, oauth, byocUrl):\n",
                "    url = f'{byocUrl}/tiles'\n",
                "\n",
                "    try:\n",
                "        while url is not None:\n",
                "            print(f'Calling url: {url}')\n",
                "            response = oauth.get(url)\n",
                "            response.raise_for_status()\n",
                "\n",
                "            output = response.json()\n",
                "            tiles = output['data']\n",
                "            links = output['links']\n",
                "\n",
                "            for tile in tiles:\n",
                "                if tile['path'].startswith(s3folder):\n",
                "                    tile_id = tile['id']\n",
                "                    response = oauth.delete(f'{byocUrl}/tiles/{tile_id}')\n",
                "                    print(\"Deleted tile: \" + tile['path'])\n",
                "                    try:\n",
                "                        response.raise_for_status()\n",
                "                    except Exception as e:\n",
                "                        print(\"Failed to delete tile {0}: {1}\".format(\n",
                "                            tile_id, response.reason))\n",
                "                        logging.error(e)\n",
                "\n",
                "            # sets url to None if there's no link to the next set of tiles\n",
                "            url = links.get('next', None)\n",
                "\n",
                "            # waits a bit before fetching the next set\n",
                "            time.sleep(0.1)\n",
                "    except Exception as e:\n",
                "        logging.error(\"BYOC delete error: {0}\".format(response.reason))\n",
                "        logging.error(e)\n",
                "        raise\n",
                "\n",
                "def insertTile(tile, oauth, byocUrl):\n",
                "    print(f'Inserting tile {tile}')\n",
                "    try:\n",
                "        response = oauth.post(f'{byocUrl}/tiles', json=tile)\n",
                "        response.raise_for_status()\n",
                "    except Exception as e:\n",
                "        logging.error(\"BYOC import error: {0}\".format(response.reason))\n",
                "        logging.error(e)\n",
                "\n",
                "\n",
                "def importToBYOC(config):\n",
                "     # Create a session\n",
                "    client = BackendApplicationClient(client_id=config['client_id'])\n",
                "    oauth = OAuth2Session(client=client)\n",
                "    oauth.fetch_token(token_url='https://services.sentinel-hub.com/oauth/token',\n",
                "                      client_id=['client_id'], client_secret=config['client_secret'])\n",
                "\n",
                "    byoc_service_base_url = config['byoc_service_base_url']\n",
                "    collection_id = config['collection_id']\n",
                "    byocUrl = f'{byoc_service_base_url}/collections/{collection_id}'\n",
                "    \n",
                "    # ingest tile\n",
                "    tilePath = config['folder']\n",
                "    tile = {\n",
                "        'path': tilePath,\n",
                "        'sensingTime': config['sensingTime'],\n",
                "        'coverGeometry' : config['coverGeometry']\n",
                "    }\n",
                "    \n",
                "    if config['coverGeometry']: \n",
                "         tile ['coverGeometry'] = config['coverGeometry']\n",
                "            \n",
                "    logging.info(\"Deleting folder: \" + tilePath)\n",
                "    deleteTile(tilePath, oauth, byocUrl)\n",
                "    logging.info(\"Ingesting folder: \" + tilePath)\n",
                "    insertTile(tile, oauth, byocUrl)\n",
                "    \n",
                "    \n",
                "def defaultBYOCImport(resultsFolder, s3Folder, resolution, sensingTime):\n",
                "    if not (resolution == 300 or resolution == 500) :\n",
                "        logger.info('Resolution not supported.')\n",
                "        return\n",
                "    \n",
                "    s3config = {\n",
                "        's3Url' : 'https://s3.waw2-1.cloudferro.com',\n",
                "        's3AccessKey' : 'xxx',\n",
                "        's3SecrestKey' : 'xxx',\n",
                "        'bucketName' : 'polar',\n",
                "        'folder' : s3Folder,\n",
                "    }\n",
                "    coverGeometry = importToBucket(s3config, resultsFolder, True)\n",
                "    \n",
                "    collectionID_300m = 'd34c470c-52a8-49db-9f9b-0956f10734d9'\n",
                "    collectionID_500m = '6a3a4f71-84ff-4421-95a7-6ba969b5cf88'\n",
                "    \n",
                "    collectionId = collectionID_300m if resolution == 300 else collectionID_500m\n",
                "    \n",
                "    shConfig = {\n",
                "        'byoc_service_base_url' : 'https://creodias.sentinel-hub.com/api/v1/byoc',\n",
                "        'client_id' : 'xxx',\n",
                "        'client_secret' : 'xxx',\n",
                "        'collection_id' : collectionId,\n",
                "        'folder' : s3Folder,\n",
                "        'sensingTime' : sensingTime,\n",
                "        'coverGeometry' : coverGeometry\n",
                "    }    \n",
                "    importToBYOC(shConfig)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "db76b5aa-66fa-41f4-9ba9-8899c364c1d4",
            "metadata": {
                "papermill": {
                    "duration": 1.161156,
                    "end_time": "2021-05-11T14:54:55.668650",
                    "exception": false,
                    "start_time": "2021-05-11T14:54:54.507494",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Various utilities\n",
                "import os\n",
                "import json\n",
                "from shapely import geometry, wkt\n",
                "import datetime as dt\n",
                "import numpy as np\n",
                "import geopandas as gpd\n",
                "import glob\n",
                "import shutil\n",
                "import logging\n",
                "import concurrent.futures\n",
                "import time\n",
                "\n",
                "from sentinelhub import SentinelHubDownloadClient, SentinelHubBatch, SentinelHubRequest, Geometry, CRS, DataCollection, MimeType, SHConfig, BBox, bbox_to_dimensions\n",
                "from shapely.geometry import Polygon\n",
                "import tarfile\n",
                "\n",
                "# create logs folder\n",
                "if not os.path.exists(\"logs\"):\n",
                "    os.makedirs(\"logs\")\n",
                "\n",
                "# right now we only log to consol\n",
                "logging.basicConfig(\n",
                "    format='%(asctime)s [%(levelname)s] %(name)s - %(message)s',\n",
                "    level=logging.INFO,\n",
                "    datefmt='%Y-%m-%d %H:%M:%S',\n",
                "    handlers=[\n",
                "        logging.FileHandler(f'logs/sice_sh_{time.strftime(\"%Y_%m_%d\",time.localtime())}.log'),\n",
                "        logging.StreamHandler()\n",
                "    ])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "e4e267d4-a887-40b5-90b8-2597c429db27",
            "metadata": {
                "tags": [
                    "parameters"
                ]
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-03-07 14:49:11 [INFO] root - Date: 2021-07-09\n",
                        "2023-03-07 14:49:11 [INFO] root - AOI: POLYGON ((-14.675905 65.792421, -14.675905 66.238873, -13.423464 66.238873, -13.423464 65.792421, -14.675905 65.792421))\n",
                        "2023-03-07 14:49:11 [INFO] root - Projection: 4326\n"
                    ]
                }
            ],
            "source": [
                "#External variables\n",
                "# Set the date of calculation\n",
                "date = \"2021-07-09\"\n",
                "\n",
                "# resolution (m) \n",
                "resolution = 1200  # minimum resolution of data is 300m\n",
                "\n",
                "#area of interest\n",
                "aoi = 'POLYGON((-53.6565 82.4951, -59.9608 82.1309, -67.7892 80.5602, -67.9606 80.0218, -67.6072 79.3014, -72.7375 78.5894, -73.5413 78.1636, -72.9428 77.3837, -69.0700 76.0128, -66.6509 75.7624, -60.3956 75.8231, -58.4311 74.8854, -55.1967 69.6980, -53.8565 68.8368, -54.2986 67.0754, -53.5562 65.6109, -52.3863 64.7989, -52.3228 64.0074, -50.2076 62.1010, -48.6300 60.7381, -45.0522 59.7674, -43.2890 59.6436, -42.4957 60.3093, -41.8486 61.5655, -41.6969 62.6486, -40.1106 63.5452, -39.9111 64.7944, -38.0777 65.4068, -36.9899 65.1987, -31.2165 67.7166, -25.8502 68.6303, -21.6517 70.0839, -20.9932 70.7880, -21.2829 72.9254, -16.9050 74.9601, -17.1213 79.6158, -10.2883 81.4244, -14.0398 81.9745, -17.8112 82.0131, -28.5252 83.7013, -40.1075 83.6651, -53.6565 82.4951))'\n",
                "aoi = \"POLYGON ((-14.675905 65.792421, -14.675905 66.238873, -13.423464 66.238873, -13.423464 65.792421, -14.675905 65.792421))\"\n",
                "#sub-area\n",
                "#aoi = 'POLYGON ((-56.045995 66.271911, -49.369389 66.271911, -49.369389 71.949832, -56.045995 71.949832, -56.045995 66.271911))'\n",
                "\n",
                "#Island\n",
                "#aoi = 'POLYGON ((-24.634498 66.588207, -13.38895 66.588207, -13.38895 63.292939, -24.634498 63.292939, -24.634498 66.588207))'\n",
                "\n",
                "#target projection of the final results\n",
                "projection = '4326' #default\n",
                "\n",
                "#projection = '3413'  #polar\n",
                " \n",
                "\n",
                "# log processing parameters - don't log any S3 information\n",
                "logging.info(f'Date: {date}')\n",
                "logging.info(f'AOI: {aoi}')\n",
                "logging.info(f'Projection: {projection}')\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "235a5142-fc65-4183-8fc1-cbe5c5c65b40",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "#verify input parameters\n",
                "\n",
                "if not date:\n",
                "    raise Exception('variable date has to be set') \n",
                "\n",
                "if not aoi:\n",
                "    raise Exception('aoi has to be set')     \n",
                "\n",
                "if not resolution:\n",
                "    raise Exception('resolution has to be set')     \n",
                "\n",
                "if resolution < 300 or resolution > 1200: \n",
                "    raise Exception('value of resolution has to be between 200 m and 1200 m')\n",
                "\n",
                "#transform period into single day    \n",
                "if '/' in date:\n",
                "    date = date[0:date.find('/')]    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "1c1eacd9-47fb-49a0-bfda-395721baf851",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-03-07 14:49:11 [INFO] root - System configuration ok.\n"
                    ]
                }
            ],
            "source": [
                "#system settings\n",
                "\n",
                "#base folder where the code is located\n",
                "USR_PATH = os.path.abspath('.')\n",
                "EVAL_SCRIPT_PATH = os.path.join(USR_PATH, 'data_fusion_olci_dem.js') \n",
                "\n",
                "#delete download folder after processing - will save space but will download all the data for each requwst (otherwise the cached tile data will be used)\n",
                "DELETE_DOWNLOAD_FOLDER = True\n",
                "\n",
                "#OUTPUT_DIR = os.path.join(USR_PATH, \"output\") #local folder\n",
                "OUTPUT_DIR = \"/home/jovyan/result-data\" # will be copied to the local folder of the user requesting the data\n",
                "\n",
                "logging.info(\"System configuration ok.\")    \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "84700520-3c9a-4633-adc9-0daba2cca5c4",
            "metadata": {
                "papermill": {
                    "duration": 0.190306,
                    "end_time": "2021-05-11T14:54:55.874185",
                    "exception": false,
                    "start_time": "2021-05-11T14:54:55.683879",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-03-07 14:49:11 [INFO] root - Configuration ok.\n"
                    ]
                }
            ],
            "source": [
                "# initial ENV configuration\n",
                "SH_CLIENT_ID = %env SH_CLIENT_ID\n",
                "SH_CLIENT_SECRET = %env SH_CLIENT_SECRET\n",
                "\n",
                "sh_config = SHConfig()\n",
                "sh_config.sh_base_url = \"https://services.sentinel-hub.com\"\n",
                "sh_config.download_timeout_seconds=300\n",
                "sh_config.download_sleep_time=20\n",
                "\n",
                "sh_config.sh_client_id = SH_CLIENT_ID\n",
                "sh_config.sh_client_secret = SH_CLIENT_SECRET\n",
                "\n",
                "sh_config.save()\n",
                "\n",
                "# Evalscript\n",
                "evalscript = \"\"\"\n",
                "//VERSION=3\n",
                "function setup() {\n",
                "  return {\n",
                "    input: [\n",
                "      {\n",
                "        datasource: \"OLCI\",\n",
                "        bands: [\"B01\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B09\", \"B10\", \"B11\", \"B12\", \"B13\", \"B14\", \"B15\", \"B16\", \"B17\", \"B18\", \"B19\", \"B20\", \"B21\", \"SZA\", \"VZA\", \"SAA\", \"VAA\", \"TOTAL_COLUMN_OZONE\"],\n",
                "      },\n",
                "      {\n",
                "        datasource: \"COP_30\",\n",
                "        bands: [\"DEM\"]\n",
                "      }\n",
                "    ],\n",
                "    output: [\n",
                "      {\n",
                "        id: \"r_TOA_01\",\n",
                "        bands: 1,\n",
                "        sampleType: \"FLOAT32\",\n",
                "      },\n",
                "      {\n",
                "        id: \"r_TOA_06\",\n",
                "        bands: 1,\n",
                "        sampleType: \"FLOAT32\",\n",
                "      },\n",
                "      {\n",
                "        id: \"r_TOA_17\",\n",
                "        bands: 1,\n",
                "        sampleType: \"FLOAT32\",\n",
                "      },\n",
                "      {\n",
                "        id: \"r_TOA_21\",\n",
                "        bands: 1,\n",
                "        sampleType: \"FLOAT32\",\n",
                "      },\n",
                "      {\n",
                "        id: \"snow_grain_diameter\",\n",
                "        bands: 1,\n",
                "        sampleType: \"FLOAT32\",\n",
                "      },\n",
                "      {\n",
                "        id: \"snow_specific_surface_area\",\n",
                "        bands: 1,\n",
                "        sampleType: \"FLOAT32\",\n",
                "      },\n",
                "      {\n",
                "        id: \"diagnostic_retrieval\",\n",
                "        bands: 1,\n",
                "        sampleType: \"UINT8\",\n",
                "      },\n",
                "      {\n",
                "        id: \"albedo_bb_planar_sw\",\n",
                "        bands: 1,\n",
                "        sampleType: \"FLOAT32\",\n",
                "      },\n",
                "      {\n",
                "        id: \"albedo_bb_spherical_sw\",\n",
                "        bands: 1,\n",
                "        sampleType: \"FLOAT32\",\n",
                "      }\n",
                "\n",
                "    ],\n",
                "    mosaicking: \"SIMPLE\",\n",
                "  };\n",
                "}\n",
                "\n",
                "//function updateOutput(outputs, collections) {\n",
                "//  Object.values(outputs).forEach((output) => {\n",
                "//    output.bands = collections.scenes.length;\n",
                "//  });\n",
                "//}\n",
                "\n",
                "// Set constants as global variables which can be used in all functions\n",
                "var wls = {\n",
                "  \"B01\": 0.4000E+00,\n",
                "  \"B02\": 0.4125E+00,\n",
                "  \"B03\": 0.4425E+00,\n",
                "  \"B04\": 0.4900E+00,\n",
                "  \"B05\": 0.5100E+00,\n",
                "  \"B06\": 0.5600E+00,\n",
                "  \"B07\": 0.6200E+00,\n",
                "  \"B08\": 0.6650E+00,\n",
                "  \"B09\": 0.6737E+00,\n",
                "  \"B10\": 0.6812E+00,\n",
                "  \"B11\": 0.7088E+00,\n",
                "  \"B12\": 0.7538E+00,\n",
                "  \"B13\": 0.7613E+00,\n",
                "  \"B14\": 0.7644E+00,\n",
                "  \"B15\": 0.7675E+00,\n",
                "  \"B16\": 0.7788E+00,\n",
                "  \"B17\": 0.8650E+00,\n",
                "  \"B18\": 0.8850E+00,\n",
                "  \"B19\": 0.9000E+00,\n",
                "  \"B20\": 0.9400E+00,\n",
                "  \"B21\": 0.1020E+01\n",
                "};\n",
                "\n",
                "var bai = {\n",
                "  \"B01\": 2.365E-11,\n",
                "  \"B02\": 2.7E-11,\n",
                "  \"B03\": 7.0E-11,\n",
                "  \"B04\": 4.17E-10,\n",
                "  \"B05\": 8.04E-10,\n",
                "  \"B06\": 2.84E-09,\n",
                "  \"B07\": 8.58E-09,\n",
                "  \"B08\": 1.78E-08,\n",
                "  \"B09\": 1.95E-08,\n",
                "  \"B10\": 2.1E-08,\n",
                "  \"B11\": 3.3E-08,\n",
                "  \"B12\": 6.23E-08,\n",
                "  \"B13\": 7.1E-08,\n",
                "  \"B14\": 7.68E-08,\n",
                "  \"B15\": 8.13E-08,\n",
                "  \"B16\": 9.88E-08,\n",
                "  \"B17\": 2.4E-07,\n",
                "  \"B18\": 3.64E-07,\n",
                "  \"B19\": 4.2E-07,\n",
                "  \"B20\": 5.53e-07,\n",
                "  \"B21\": 2.25E-06\n",
                "}\n",
                "\n",
                "let emptyBandObject = {\n",
                "  \"B01\": {},\n",
                "  \"B02\": {},\n",
                "  \"B03\": {},\n",
                "  \"B04\": {},\n",
                "  \"B05\": {},\n",
                "  \"B06\": {},\n",
                "  \"B07\": {},\n",
                "  \"B08\": {},\n",
                "  \"B09\": {},\n",
                "  \"B10\": {},\n",
                "  \"B11\": {},\n",
                "  \"B12\": {},\n",
                "  \"B13\": {},\n",
                "  \"B14\": {},\n",
                "  \"B15\": {},\n",
                "  \"B16\": {},\n",
                "  \"B17\": {},\n",
                "  \"B18\": {},\n",
                "  \"B19\": {},\n",
                "  \"B20\": {},\n",
                "  \"B21\": {}\n",
                "}\n",
                "\n",
                "const allBands = Object.keys(bai);\n",
                "\n",
                "// solar spectrum constants\n",
                "const f0 = 32.38;\n",
                "const f1 = -160140.33;\n",
                "const f2 = 7959.53;\n",
                "const bet = 1. / (85.34 * 1.e-3);\n",
                "const gam = 1. / (401.79 * 1.e-3);\n",
                "\n",
                "var coef1, coef2 = analyt_func(0.3, 0.7);\n",
                "var coef3, coef4 = analyt_func(0.7, 0.865);\n",
                "\n",
                "function evaluatePixel(samples) {\n",
                "  const n_acquisitions = samples.OLCI.length;\n",
                "  const olciSamples = samples.OLCI;\n",
                "  const demSamples = samples.COP_30;\n",
                "  let r_TOA_01_valid = [];\n",
                "  let r_TOA_06_valid = [];\n",
                "  let r_TOA_17_valid = [];\n",
                "  let r_TOA_21_valid = [];\n",
                "  let snow_grain_diameter = [];\n",
                "  let snow_specific_surface_area = [];\n",
                "\n",
                "  // new products\n",
                "  let diagnostic_retrieval = [];\n",
                "  let albedo_bb_planar_sw = [];\n",
                "  let albedo_bb_spherical_sw = [];\n",
                "\n",
                "\n",
                "\n",
                "  // Loop through acquisition dates. No need to use this for single acquisition processing.\n",
                "  for (aq = 0; aq < n_acquisitions; aq++) {\n",
                "    // Correct TOA reflectance for ozone absorption\n",
                "    sample_cor_o3 = ozone_correction(olciSamples[aq]);\n",
                "\n",
                "    //Transfer of OLCI relative azimuthal angle to the definition used in radiative transfer code\n",
                "    angles = view_geometry(olciSamples[aq]);\n",
                "\n",
                "    //Filtering pixels unsuitable for retrieval\n",
                "    [snow, sample_fltr] = prepare_processing(sample_cor_o3, demSamples[0]);\n",
                "\n",
                "    //Compute snow properties\n",
                "    [sample_valid, angles_valid, snow] = snow_properties(sample_fltr, angles, snow);\n",
                "\n",
                "    //Compute aerosol\n",
                "    aerosol = aerosol_properties(demSamples[0].DEM, angles_valid.cos_sa);\n",
                "\n",
                "    //Compute atmosphere\n",
                "    atmosphere = prepare_coef(aerosol, angles);\n",
                "\n",
                "    //Compute theoretical reflectance of snow from albedo\n",
                "    snow = clean_snow_albedo(sample_valid, angles, aerosol, atmosphere, snow);\n",
                "\n",
                "    //throw new Error(JSON.stringify(snow))\n",
                "\n",
                "    snow = polluted_snow_albedo(sample_valid, angles, aerosol, atmosphere, snow);\n",
                "\n",
                "    snow = compute_plane_albedo(snow, angles);\n",
                "\n",
                "    r_TOA_01_valid.push(sample_valid.B01);\n",
                "    r_TOA_06_valid.push(sample_valid.B06);\n",
                "    r_TOA_17_valid.push(sample_valid.B17);\n",
                "    r_TOA_21_valid.push(sample_valid.B21);\n",
                "    snow_grain_diameter.push(snow.diameter);\n",
                "    snow_specific_surface_area.push(snow.area);\n",
                "    diagnostic_retrieval.push(snow.isnow);\n",
                "    albedo_bb_planar_sw.push(snow.rp3);\n",
                "    albedo_bb_spherical_sw.push(snow.rs3);\n",
                "\n",
                "    // Development use. Allow you to check the output before the script is finished.\n",
                "    //throw new Error(JSON.stringify(snow))\n",
                "  }\n",
                "  return {\n",
                "    r_TOA_01: r_TOA_01_valid,\n",
                "    r_TOA_06: r_TOA_06_valid,\n",
                "    r_TOA_17: r_TOA_17_valid,\n",
                "    r_TOA_21: r_TOA_21_valid,\n",
                "    snow_grain_diameter: snow_grain_diameter,\n",
                "    snow_specific_surface_area: snow_specific_surface_area,\n",
                "    diagnostic_retrieval: diagnostic_retrieval,\n",
                "    albedo_bb_planar_sw: albedo_bb_planar_sw,\n",
                "    albedo_bb_spherical_sw: albedo_bb_spherical_sw\n",
                "  };\n",
                "}\n",
                "\n",
                "function deg2rad(deg) {\n",
                "  const pi = Math.PI;\n",
                "  return deg * (pi / 180);\n",
                "}\n",
                "\n",
                "function ozone_correction(sample) {\n",
                "  const tozone_dict = {\n",
                "    \"B01\": 1.378170469E-004,\n",
                "    \"B02\": 3.048780958E-004,\n",
                "    \"B03\": 1.645714060E-003,\n",
                "    \"B04\": 8.935947110E-003,\n",
                "    \"B05\": 1.750535146E-002,\n",
                "    \"B06\": 4.347104369E-002,\n",
                "    \"B07\": 4.487130794E-002,\n",
                "    \"B08\": 2.101591797E-002,\n",
                "    \"B09\": 1.716230955E-002,\n",
                "    \"B10\": 1.466298300E-002,\n",
                "    \"B11\": 7.983028470E-003,\n",
                "    \"B12\": 3.879744653E-003,\n",
                "    \"B13\": 2.923775641E-003,\n",
                "    \"B14\": 2.792211429E-003,\n",
                "    \"B15\": 2.729651478E-003,\n",
                "    \"B16\": 3.255969698E-003,\n",
                "    \"B17\": 8.956858078E-004,\n",
                "    \"B18\": 5.188799343E-004,\n",
                "    \"B19\": 6.715773241E-004,\n",
                "    \"B20\": 3.127781417E-004,\n",
                "    \"B21\": 1.408798425E-005\n",
                "  };\n",
                "  let toa_cor_o3 = {};\n",
                "  // Loop through OLCI bands\n",
                "  allBands.forEach(band => {\n",
                "    todadu = sample.TOTAL_COLUMN_OZONE * 46696.24;\n",
                "    inv_cos_za = 1 / Math.cos(deg2rad(sample.SZA)) + 1 / Math.cos(deg2rad(sample.VZA));\n",
                "    toa_cor_o3[band] = sample[band] * 1 * Math.exp(inv_cos_za * tozone_dict[band] * todadu / 404.59);\n",
                "  });\n",
                "\n",
                "  toa_cor_o3.SZA = sample.SZA;\n",
                "  toa_cor_o3.VZA = sample.VZA;\n",
                "  toa_cor_o3.SAA = sample.SAA;\n",
                "  toa_cor_o3.VAA = sample.VAA;\n",
                "  return toa_cor_o3;\n",
                "}\n",
                "\n",
                "function view_geometry(sample) {\n",
                "  const raa = 180 - (sample.VAA - sample.SAA);\n",
                "  const sin_sza = Math.sin(deg2rad(sample.SZA));\n",
                "  const sin_vza = Math.sin(deg2rad(sample.VZA));\n",
                "  const cos_sza = Math.cos(deg2rad(sample.SZA));\n",
                "  const cos_vza = Math.cos(deg2rad(sample.VZA));\n",
                "  const ak1 = 3 * (1 + 2 * cos_sza) / 7;\n",
                "  const ak2 = 3 * (1 + 2 * cos_vza) / 7;\n",
                "  const cos_raa = Math.cos(deg2rad(raa));\n",
                "  const inv_cos_za = 1 / cos_sza + 1 / cos_vza;\n",
                "  const cos_sa = -cos_sza * cos_vza + sin_sza * sin_vza * cos_raa;\n",
                "  return {\n",
                "    raa: raa,\n",
                "    cos_sza: cos_sza,\n",
                "    cos_vza: cos_vza,\n",
                "    ak1: ak1,\n",
                "    ak2: ak2,\n",
                "    inv_cos_za: inv_cos_za,\n",
                "    cos_sa: cos_sa\n",
                "  };\n",
                "}\n",
                "\n",
                "function prepare_processing(sample_cor, sample_dem) {\n",
                "  let snow = {};\n",
                "  let sample_fltr = {};\n",
                "\n",
                "  // Assign diagnostic code\n",
                "  snow.isnow = sample_cor.B21 < 0.1 ? 102 : NaN;\n",
                "  snow.isnow = sample_cor.SZA > 75 ? 100 : snow.isnow;\n",
                "  const mask = isNaN(snow.isnow);\n",
                "\n",
                "  // Loop through OLCI bands\n",
                "  allBands.forEach(band => {\n",
                "    sample_fltr[band] = (mask == true) ? sample_cor[band] : NaN;\n",
                "  });\n",
                "\n",
                "  // Add elevation info to the object\n",
                "  sample_fltr.elevation = (mask == true) ? sample_dem.DEM : NaN;\n",
                "  return [\n",
                "    snow,\n",
                "    sample_fltr\n",
                "  ];\n",
                "}\n",
                "\n",
                "function snow_properties(sample_fltr, angles, snow) {\n",
                "  const akap2 = 2.25e-6;\n",
                "  const alpha2 = 4 * Math.PI * akap2 / 1.020;\n",
                "  const eps = 1.549559365010611;\n",
                "  const rr1 = sample_fltr.B17;\n",
                "  const rr2 = sample_fltr.B21;\n",
                "  const ak1 = angles.ak1;\n",
                "  const ak2 = angles.ak2;\n",
                "  const r0 = Math.pow(rr1, eps) * Math.pow(rr2, (1 - eps));\n",
                "  const bal = Math.pow((Math.log(rr2 / r0) / (ak1 * ak2 / r0)), 2) / alpha2;\n",
                "  const al = bal / 1000;\n",
                "  const D = al / (9.2 * 16 / 9);\n",
                "  const area = 6 / D / 0.917;\n",
                "\n",
                "  //Filtering small D\n",
                "  const diameter_thresh = 0.01;\n",
                "  const valid = D >= diameter_thresh;\n",
                "  snow.isnow = (!valid && isNaN(snow.isnow)) ? 104 : snow.isnow;\n",
                "\n",
                "  //Loop through toa bands\n",
                "  let sample_valid = {};\n",
                "\n",
                "  allBands.forEach(band => {\n",
                "    sample_valid[band] = valid ? sample_fltr[band] : NaN;\n",
                "  });\n",
                "\n",
                "  //Assign valid snow properties\n",
                "  snow.diameter = valid ? D : NaN;\n",
                "  snow.area = valid ? area : NaN;\n",
                "  snow.al = valid ? al : NaN;\n",
                "  snow.r0 = valid ? r0 : NaN;\n",
                "  snow.bal = valid ? bal : NaN;\n",
                "\n",
                "  //Loop through angles attributes\n",
                "  let angles_valid = {};\n",
                "  const angles_attrs = Object.keys(angles);\n",
                "  for (attr = 0; attr < angles_attrs.length; attr++) {\n",
                "    angles_valid[angles_attrs[attr]] = valid ? angles[angles_attrs[attr]] : NaN;\n",
                "  }\n",
                "  return [\n",
                "    sample_valid,\n",
                "    angles_valid,\n",
                "    snow\n",
                "  ];\n",
                "}\n",
                "\n",
                "function aerosol_properties(height, cos_sa, aot = 0.1) {\n",
                "  // Set an aerosol object to store the result. \n",
                "  let aerosol = {\n",
                "    \"tau\": {},\n",
                "    \"p\": {},\n",
                "    \"g\": {},\n",
                "    \"gaer\": {},\n",
                "    \"taumol\": {},\n",
                "    \"tauaer\": {}\n",
                "  };\n",
                "\n",
                "  // Loop through OLCI bands\n",
                "  allBands.forEach(band => {\n",
                "    tauaer = aot * Math.pow((wls[band] / 0.5), -1.3);\n",
                "    g0 = 0.5263;\n",
                "    g1 = 0.4627;\n",
                "    wave0 = 0.4685;\n",
                "    gaer = g0 + g1 * Math.exp(-wls[band] / wave0);\n",
                "    pr = 0.75 * (1 + Math.pow(cos_sa, 2));\n",
                "    taumol = Math.pow(wls[band], -4.05) * Math.min(1, Math.exp(-height / 7400)) * 0.00877;\n",
                "    tau = tauaer + taumol;\n",
                "    g = tauaer * gaer / tau;\n",
                "    pa = (1 - Math.pow(g, 2)) / Math.pow((1 - 2 * g * cos_sa + Math.pow(g, 2)), 1.5);\n",
                "    p = (taumol * pr + tauaer * pa) / tau;\n",
                "\n",
                "    // Assign results to objects. Values can be called via, e.g., aerosol.tau.B01\n",
                "    Object.assign(aerosol.tau, { [band]: tau })\n",
                "    Object.assign(aerosol.p, { [band]: p })\n",
                "    Object.assign(aerosol.g, { [band]: g })\n",
                "    Object.assign(aerosol.gaer, { [band]: gaer })\n",
                "    Object.assign(aerosol.taumol, { [band]: taumol })\n",
                "    Object.assign(aerosol.tauaer, { [band]: tauaer })\n",
                "  });\n",
                "  return aerosol;\n",
                "}\n",
                "\n",
                "// Solar flux\n",
                "function sol(x) {\n",
                "  // SOLAR SPECTRUM at GROUND level\n",
                "  // Inputs:\n",
                "  // x - wave length in micrometer\n",
                "  // Outputs: \n",
                "  // sol - solar spectrum in W m-2 micrometer-1 (?)\n",
                "  sol1a = f0 * x;\n",
                "  sol1b = - f1 * Math.exp(-bet * x) / bet;\n",
                "  sol1c = - f2 * Math.exp(-gam * x) / gam;\n",
                "  return sol1a + sol1b + sol1c;\n",
                "}\n",
                "\n",
                "function analyt_func(z1, z2) {\n",
                "  // see BBA_calc_pol\n",
                "  // compatible with array\n",
                "  var gam2 = Math.exp(gam, 2);\n",
                "  var gam3 = Math.exp(gam, 3);\n",
                "\n",
                "  var z12 = Math.exp(z1, 2);\n",
                "  var z13 = Math.exp(z1, 3);\n",
                "\n",
                "  var z22 = Math.exp(z2, 2);\n",
                "  var z23 = Math.exp(z2, 3);\n",
                "\n",
                "  var bet2 = Math.exp(bet, 2);\n",
                "  var bet3 = Math.exp(bet, 3);\n",
                "\n",
                "  var ak1 = (z22 - z12) / 2.0;\n",
                "  var ak2 = (z2 / bet + 1.0 / bet2) * Math.exp(-bet * z2) - (z1 / bet + 1.0 / bet2) * Math.exp(-bet * z1);\n",
                "  var ak3 = (z2 / gam + 1.0 / gam2) * Math.exp(-gam * z2) - (z1 / gam + 1.0 / gam2) * Math.exp(-gam * z1);\n",
                "  var am_minus = (z12 / bet + 2.0 * z1 / bet2 + 2.0 / bet3) * Math.exp(-bet * z1);\n",
                "\n",
                "  var am1 = (z23 - z13) / 3.0;\n",
                "  var am2 = (z22 / bet + 2.0 * z2 / bet2 + 2.0 / bet3) * Math.exp(-bet * z2) - am_minus\n",
                "  var am3 = (z22 / gam + 2.0 * z2 / gam2 + 2.0 / gam3) * Math.exp(-gam * z2) - am_minus;\n",
                "\n",
                "  return (f0 * ak1 - f1 * ak2 - f2 * ak3), (f0 * am1 - f1 * am2 - f2 * am3);\n",
                "}\n",
                "\n",
                "function prepare_coef(aerosol, angles) {\n",
                "  // Set an atmosphere object \n",
                "  let atmosphere = {\n",
                "    \"t1\": {},\n",
                "    \"t2\": {},\n",
                "    \"ratm\": {},\n",
                "    \"r\": {}\n",
                "  };\n",
                "\n",
                "  // Loop through OLCI bands\n",
                "  allBands.forEach(band => {\n",
                "    tau = aerosol.tau[band];\n",
                "    g = aerosol.g[band];\n",
                "    p = aerosol.p[band];\n",
                "    cos_sza = angles.cos_sza;\n",
                "    cos_vza = angles.cos_vza;\n",
                "    inv_cos_za = angles.inv_cos_za;\n",
                "\n",
                "    one_g_tau = (1 - g) * tau;\n",
                "\n",
                "    b1 = 1 + 1.5 * cos_sza + (1 - 1.5 * cos_sza) * Math.exp(-tau / cos_sza);\n",
                "    b2 = 1 + 1.5 * cos_vza + (1 - 1.5 * cos_vza) * Math.exp(-tau / cos_vza);\n",
                "\n",
                "    sumcos = cos_sza + cos_vza;\n",
                "\n",
                "    astra = (1 - Math.exp(-tau * inv_cos_za)) / sumcos / 4;\n",
                "    oskar = 4 + 3 * one_g_tau;\n",
                "\n",
                "    rms = 1 - b1 * b2 / oskar + (3 * (1 + g) * (cos_sza * cos_vza) - 2 * sumcos) * astra;\n",
                "\n",
                "    r = p * astra + rms;\n",
                "\n",
                "    wa1 = 1.10363;\n",
                "    wa2 = -6.70122;\n",
                "    wx0 = 2.19777;\n",
                "    wdx = 0.51656;\n",
                "    bex = Math.exp((g - wx0) / wdx);\n",
                "\n",
                "    arg = -0.5 * one_g_tau / ((wa1 - wa2) / (1 + bex) + wa2);\n",
                "\n",
                "    t1 = Math.exp(arg / cos_sza);\n",
                "    t2 = Math.exp(arg / cos_vza);\n",
                "\n",
                "    a_s = [.18016, -0.18229, 0.15535, -0.14223];\n",
                "    bs = [.58331, -0.50662, -0.09012, 0.0207];\n",
                "    cs = [0.21475, -0.1, 0.13639, -0.21948];\n",
                "    als = [0.16775, -0.06969, 0.08093, -0.08903];\n",
                "    bets = [1.09188, 0.08994, 0.49647, -0.75218];\n",
                "\n",
                "    a_cst = a_s[0] + a_s[1] * g;\n",
                "    b_cst = bs[0] + bs[1] * g;\n",
                "    c_cst = cs[0] + cs[1] * g;\n",
                "    al_cst = als[0] + als[1] * g;\n",
                "    bet_cst = bets[0] + bets[1] * g;\n",
                "\n",
                "    for (num = 2; num < 4; num++) {\n",
                "      if (num == 2) {\n",
                "        gg = Math.pow(g, 2);\n",
                "      } else {\n",
                "        gg *= g;\n",
                "      }\n",
                "      a_cst += a_s[num] * gg\n",
                "      b_cst += bs[num] * gg\n",
                "      c_cst += cs[num] * gg\n",
                "      al_cst += als[num] * gg\n",
                "      bet_cst += bets[num] * gg\n",
                "    }\n",
                "    ratm = tau * (a_cst * Math.exp(-tau / al_cst) + b_cst * Math.exp(-tau / bet_cst) + c_cst)\n",
                "\n",
                "    // Assign the results to the objects\n",
                "    Object.assign(atmosphere.t1, { [band]: t1 });\n",
                "    Object.assign(atmosphere.t2, { [band]: t2 });\n",
                "    Object.assign(atmosphere.ratm, { [band]: ratm });\n",
                "    Object.assign(atmosphere.r, { [band]: r });\n",
                "  });\n",
                "\n",
                "  return atmosphere;\n",
                "}\n",
                "\n",
                "function alb2rtoa(a, t1, t2, r0, ak1, ak2, ratm, r) {\n",
                "  const surf = t1 * t2 * r0 * Math.pow(a, (ak1 * ak2 / r0)) / (1 - a * ratm);\n",
                "  const rs = r + surf;\n",
                "  return rs;\n",
                "}\n",
                "\n",
                "function clean_snow_albedo(sample_valid, angles, aerosol, atmosphere, snow) {\n",
                "  snow.rs_1 = alb2rtoa(1, atmosphere.t1.B01, atmosphere.t2.B01, 1, 1, 1, atmosphere.ratm.B01, atmosphere.r.B01);\n",
                "  snow.ind_clean = sample_valid.B01 >= snow.rs_1;\n",
                "  snow.isnow = (snow.ind_clean) ? 0 : snow.isnow;\n",
                "  snow.ind_pol = sample_valid.B01 < snow.rs_1;\n",
                "\n",
                "  var alb_sph = Object.assign({}, emptyBandObject);\n",
                "  allBands.forEach(band => {\n",
                "    alb_sph[band] = Math.min(Math.exp(-Math.sqrt(1000 * 4 * Math.PI * (bai[band] / wls[band] * snow.al))), 1);\n",
                "  });\n",
                "\n",
                "  // Assign the results to the objects\n",
                "  snow.alb_sph = alb_sph;\n",
                "  return snow;\n",
                "}\n",
                "\n",
                "function polluted_snow_albedo(sample_valid, angles, aerosol, atmosphere, snow) {\n",
                "  //throw new Error(JSON.stringify(sample_valid));\n",
                "\n",
                "  if (snow.ind_pol) {\n",
                "    snow.isnow = (snow.ind_pol) ? 1 : snow.isnow;\n",
                "    ind_very_dark = (sample_valid.B21 < 0.4 && snow.ind_pol);\n",
                "    snow.isnow = (ind_very_dark) ? 6 : snow.isnow;\n",
                "    snow.r0 = (!ind_very_dark) ? snow.isnow : compute_rclean(angles.cos_sza, angles.cos_vza, angles.cos_sa, angles.raa);\n",
                "    //snow.alb_sph = (snow.ind_pol) ? 1 : snow.alb_sph; Guess it applies to all bands\n",
                "    Object.keys(snow.alb_sph).forEach(band => {\n",
                "      snow.alb_sph[band] = (snow.ind_pol) ? 1 : snow.alb_sph[band]\n",
                "    })\n",
                "\n",
                "    const bands_to_loop_over = Object.keys(sample_valid);\n",
                "    bands_to_loop_over.splice(18, 2);\n",
                "\n",
                "    //throw new Error(JSON.stringify(bands_to_loop_over));\n",
                "\n",
                "    for (i = 0; i < bands_to_loop_over.length; i++) {\n",
                "      var band = bands_to_loop_over[i];\n",
                "      snow.alb_sph[band] = (snow.ind_pol) ? solver_wrapper(sample_valid[band], atmosphere.t1[band], atmosphere.t2[band], snow.r0, angles.ak1, angles.ak2, atmosphere.ratm[band], atmosphere.r[band]) : snow.alb_sph[band];\n",
                "      snow.isnow = snow.alb_sph[band] == -999 ? -(i + 1) : snow.isnow;\n",
                "    }\n",
                "\n",
                "    // Guess it applies to all bands\n",
                "    Object.keys(snow.alb_sph).forEach(band => {\n",
                "      snow.alb_sph[band] = snow.isnow ? snow.alb_sph[band] : NaN;\n",
                "    })\n",
                "\n",
                "    let ind_clear_pol = (snow.alb_sph.B01 > 0.98 | snow.alb_sph.B02 > 0.98) & snow.ind_pol;\n",
                "    snow.isnow = ind_clear_pol ? 7 : snow.isnow;\n",
                "\n",
                "    // Guess it applies to all bands\n",
                "    if (!ind_clear_pol) {\n",
                "      allBands.forEach(band => {\n",
                "        snow.alb_sph[band] = Math.exp(-Math.sqrt(4 * 1000 * Math.PI * snow.al * (bai[band] / wls[band])));\n",
                "      });\n",
                "    }\n",
                "\n",
                "    snow.ind_pol = snow.ind_pol & (snow.isnow != 7);\n",
                "\n",
                "    // reprocessing of albedo to remove gaseous absorption using linear polynomial approximation in the range 753-778nm.\n",
                "    // Meaning: alb_sph[12],alb_sph[13] and alb_sph[14] are replaced by a linear  interpolation between alb_sph[11] and alb_sph[15]\n",
                "    if (ind_clear_pol) {\n",
                "      afirn = snow.alb_sph['B15'] - snow.alb_sph['B11'] / (wls['B15'] - wls['B11']);\n",
                "      bfirn = snow.alb_sph['B15'] - afirn * wls['B15'];\n",
                "\n",
                "      // indeces of bands start with 0!\n",
                "      allBands.concat().splice(11, 3).forEach(band => {\n",
                "        snow.alb_sph[band] = bfirn + afirn * wls[band];\n",
                "      });\n",
                "    }\n",
                "\n",
                "    // pixels that are clean enough in channels 18 19 20 and 21 are not affected by pollution, the analytical equation can then be used\n",
                "    ind_ok = (sample_valid.B20 > 0.35) & snow.ind_pol;\n",
                "    if (ind_ok) {\n",
                "      allBands.concat().splice(17, 4).forEach(band => {\n",
                "        snow.alb_sph[band] = Math.exp(-Math.sqrt(4. * 1000. * Math.PI * snow.al * (bai[band] / wls[band])));\n",
                "      });\n",
                "    }\n",
                "\n",
                "    //to avoid the influence of gaseous absorption (water vapor) we linearly interpolate in the range 885-1020nm for bare ice cases only (low toa[20])\n",
                "    //Meaning: alb_sph[18] and alb_sph[19] are replaced by a linear interpolation between alb_sph[17] and alb_sph[20]\n",
                "    if (ind_ok) {\n",
                "      bcoef = (snow.alb_sph['B20'] - snow.alb_sph['B17']) / (wls['B20'] - wls['17'])\n",
                "      acoef = snow.alb_sph['B20'] - bcoef * wls['B20']\n",
                "      allBands.concat().splice(17, 2).forEach(band => {\n",
                "        snow.alb_sph[band] = acoef + bcoef * wls[band];\n",
                "      });\n",
                "    }\n",
                "  }\n",
                "  return snow;\n",
                "}\n",
                "\n",
                "function compute_plane_albedo(snow, angles) {\n",
                "  var rp = Object.assign({}, emptyBandObject);\n",
                "  var refl = Object.assign({}, emptyBandObject);\n",
                "\n",
                "  snow.rp = rp;\n",
                "  snow.refl = refl;\n",
                "\n",
                "  allBands.forEach(band => {\n",
                "    snow.rp[band] = Math.pow(snow.alb_sph[band], angles.ak1);\n",
                "    snow.refl[band] = snow.r0[band] * Math.pow(snow.alb_sph[band], angles.ak1 * angles.ak2 / snow.r0);\n",
                "  });\n",
                "\n",
                "  ind_all_clean = snow.ind_clean || (snow.isnow == 7);\n",
                "\n",
                "\n",
                "  if (ind_all_clean) {\n",
                "    snow.rp3 = plane_albedo_sw_approx(snow.diameter, angles.cos_sza);\n",
                "    snow.rs3 = spher_albedo_sw_approx(snow.diameter);\n",
                "  }\n",
                "\n",
                "  // solar flux calculation\n",
                "  // sol1      visible(0.3 - 0.7micron)\n",
                "  // somehow, a different sol1 needs to be used for clean snow and polluted snow\n",
                "  var sol1_pol = sol(0.7) - sol(0.3);\n",
                "  // sol2      near - infrared(0.7 - 2.4micron)\n",
                "  // same for clean and polluted\n",
                "  var sol2 = sol(2.4) - sol(0.7);\n",
                "\n",
                "  // sol3      shortwave(0.3 - 2.4 micron)\n",
                "  // sol3 is also different for clean snow and polluted snow\n",
                "  var sol3_pol = sol1_pol + sol2;\n",
                "\n",
                "  // asol specific band\n",
                "  var asol = sol(0.865) - sol(0.7);\n",
                "\n",
                "  if (snow.ind_pol) {\n",
                "    snow.rp3 = BBA_calc_pol(snow.rp, asol, sol1_pol, sol3_pol);\n",
                "    snow.rs3 = BBA_calc_pol(snow.alb_sph, asol, sol1_pol, sol3_pol);\n",
                "  }\n",
                "\n",
                "  return snow;\n",
                "}\n",
                "\n",
                "function BBA_calc_pol(alb, asol, sol1_pol, sol3_pol) {\n",
                "  // polluted snow\n",
                "  // NEW CODE FOR BBA OF BARE ICE\n",
                "  // alb is either the planar or spherical albedo\n",
                "\n",
                "  // ANAlYTICal EQUATION FOR THE NOMINATOR\n",
                "  // integration over 3 segments\n",
                "\n",
                "  // segment 1\n",
                "  // QUADRATIC POLYNOMIal for the range 400 - 709nm\n",
                "  // input wavelength\n",
                "  //    alam2 = w[0]\n",
                "  //    alam3 = w[5]\n",
                "  //    alam5 = w[10]\n",
                "  //    alam6 = w[11]\n",
                "  //    alam7 = w[16]\n",
                "  //    alam8 = w[20]\n",
                "\n",
                "  const alam2 = 0.4;\n",
                "  const alam3 = 0.56;\n",
                "  const alam5 = 0.709;\n",
                "  const alam6 = 0.753;\n",
                "  const alam7 = 0.865;\n",
                "  const alam8 = 1.02;\n",
                "\n",
                "  // input reflectances\n",
                "  var r2 = alb['B01'];\n",
                "  var r3 = alb['B05'];\n",
                "  var r5 = alb['B10'];\n",
                "  var r6 = alb['B011'];\n",
                "  var r7 = alb['B16'];\n",
                "  var r8 = alb['B20'];\n",
                "\n",
                "  // declared outside\n",
                "  //var coef1, coef2 = analyt_func(0.3, 0.7);\n",
                "  //var coef3, coef4 = analyt_func(0.7, 0.865);\n",
                "\n",
                "  var a1, b1, c1 = quad_func(alam2, alam3, alam5, r2, r3, r5)\n",
                "  var aj1 = a1 * sol1_pol + b1 * coef1 + c1 * coef2;\n",
                "\n",
                "  // segment 2.1\n",
                "  // QUADRATIC POLYNOMIal for the range 709 - 865nm\n",
                "  var a2, b2, c2 = quad_func(alam5, alam6, alam7, r5, r6, r7)\n",
                "  var aj2 = a2 * asol + b2 * coef3 + c2 * coef4;    // segment 2.2\n",
                "\n",
                "  // exponential approximation for the range 865 - 2400 nm\n",
                "  const z1 = 0.865;\n",
                "  const z2 = 2.4;\n",
                "  var rati = r7 / r8;\n",
                "  var alasta = (alam8 - alam7) / Math.log(rati);\n",
                "  var an = 1. / alasta;\n",
                "  var p = r7 * Math.exp(alam7 / alasta);\n",
                "\n",
                "  var aj31 = (1. / an) * (Math.exp(-an * z2) - Math.exp(-an * z1));\n",
                "  var aj32 = (1. / (bet + an)) * (Math.exp(-(bet + an) * z2) - Math.exp(-(an + bet) * z1));\n",
                "  var aj33 = (1. / (gam + an)) * (Math.exp(-(gam + an) * z2) - Math.exp(-(an + gam) * z1));\n",
                "  var aj3 = (-f0 * aj31 - f1 * aj32 - f2 * aj33) * p;\n",
                "\n",
                "  return (aj1 + aj2 + aj3) / sol3_pol;\n",
                "}\n",
                "\n",
                "function quad_func(x0, x1, x2, y0, y1, y2) {\n",
                "  // quadratic function used for the polluted snow BBA calculation\n",
                "  // see BBA_calc_pol\n",
                "  // compatible with arrays\n",
                "  var d1 = (x0 - x1) * (x0 - x2);\n",
                "  var d2 = (x1 - x0) * (x1 - x2);\n",
                "  var d3 = (x2 - x0) * (x2 - x1);\n",
                "\n",
                "  var a1 = x1 * x2 * y0 / d1 + x0 * x2 * y1 / d2 + x0 * x1 * y2 / d3;\n",
                "  var b1 = -(x1 + x2) * y0 / d1 - (x0 + x2) * y1 / d2 - (x0 + x1) * y2 / d3;\n",
                "  var c1 = y0 / d1 + y1 / d2 + y2 / d3;\n",
                "  var x = x1;\n",
                "  return a1, b1, c1;\n",
                "}\n",
                "\n",
                "function spher_albedo_sw_approx(D) {\n",
                "  return 0.6420 + 0.1044 * Math.exp(-1000 * D / 158.62) + 0.1773 * Math.exp(-1000 * D / 2448.18);\n",
                "}\n",
                "\n",
                "function plane_albedo_sw_approx(D, cos_sza) {\n",
                "  var cos_sza2 = Math.exp(cos_sza, 2);\n",
                "  var anka = 0.7389 - 0.1783 * cos_sza + 0.0484 * cos_sza2;\n",
                "  var banka = 0.0853 + 0.0414 * cos_sza - 0.0127 * cos_sza2\n",
                "  var canka = 0.1384 + 0.0762 * cos_sza - 0.0268 * cos_sza2;\n",
                "  var diam1 = 187.89 - 69.2636 * cos_sza + 40.4821 * cos_sza2;\n",
                "  var diam2 = 2687.25 - 405.09 * cos_sza + 94.5 * cos_sza2;\n",
                "  return anka + banka * Math.exp(-1000 * D / diam1) + canka * Math.exp(-1000 * D / diam2)\n",
                "}\n",
                "\n",
                "function compute_rclean(cos_sza, cos_vza, cos_sa, raa) {\n",
                "  const am11 = Math.sqrt(1 - Math.pow(cos_sza, 2));\n",
                "  const am12 = Math.sqrt(1 - Math.pow(cos_vza, 2));\n",
                "  const theta = Math.acos(-cos_sza * cos_vza + am11 * am12 * Math.cos(raa * 3.14159 / 180)) * 180 / Math.PI;\n",
                "  const pz = 11.1 * Math.exp(-0.087 * theta) + 1.1 * Math.exp(-0.014 * theta);\n",
                "  const sumcos = cos_sza + cos_vza;\n",
                "  const rclean = 1.247 + 1.186 * sumcos + 5.157 * cos_sza * cos_vza + pz;\n",
                "  return rclean / 4 / sumcos;\n",
                "}\n",
                "\n",
                "function solver_wrapper(toa_cor_o3, t1, t2, r0, ak1, ak2, ratm, r) {\n",
                "  return zbrent(0.1, 1, args = [t1, t2, r0, ak1, ak2, ratm, r, toa_cor_o3], max_iter = 30, tolerance = 2e-4);\n",
                "}\n",
                "\n",
                "function zbrent(x0, x1, args, max_iter = 100, tolerance = 1e-6) {\n",
                "  let fx0 = f(x0, ...args = args);\n",
                "  let fx1 = f(x1, ...args = args);\n",
                "  if ((fx0 * fx1) > 0) {\n",
                "    return -999;\n",
                "  }\n",
                "  if (Math.abs(fx0) < Math.abs(fx1)) {\n",
                "    [x0, x1] = [x1, x0];\n",
                "    [fx0, fx1] = [fx1, fx0];\n",
                "  }\n",
                "  let [x2, fx2] = [x0, fx0];\n",
                "  let d = x2;\n",
                "  let mflag = true;\n",
                "  let steps_taken = 0;\n",
                "  while (steps_taken < max_iter && Math.abs(x1 - x0) > tolerance) {\n",
                "    fx0 = f(x0, ...args = args);\n",
                "    fx1 = f(x1, ...args = args);\n",
                "    fx2 = f(x2, ...args = args);\n",
                "\n",
                "    if (fx0 != fx2 && fx1 != fx2) {\n",
                "      let L0 = (x0 * fx1 * fx2) / ((fx0 - fx1) * (fx0 - fx2));\n",
                "      let L1 = (x1 * fx0 * fx2) / ((fx1 - fx0) * (fx1 - fx2));\n",
                "      let L2 = (x2 * fx1 * fx0) / ((fx2 - fx0) * (fx2 - fx1));\n",
                "      var new_value = L0 + L1 + L2;\n",
                "    } else {\n",
                "      var new_value = x1 - ((fx1 * (x1 - x0)) / (fx1 - fx0));\n",
                "    }\n",
                "\n",
                "    if (\n",
                "      (new_value < ((3 * x0 + x1) / 4) || new_value > x1) ||\n",
                "      (mflag == true && (Math.abs(new_value - x1)) >= (Math.abs(x1 - x2) / 2)) ||\n",
                "      (mflag == false && (Math.abs(new_value - x1)) >= (Math.abs(x2 - d) / 2)) ||\n",
                "      (mflag == true && (Math.abs(x1 - x2)) < tolerance) ||\n",
                "      (mflag == false && (Math.abs(x2 - d)) < tolerance)\n",
                "    ) {\n",
                "      new_value = (x0 + x1) / 2;\n",
                "      mflag = true;\n",
                "    } else {\n",
                "      mflag = false;\n",
                "    }\n",
                "\n",
                "    let fnew = f(new_value, ...args = args);\n",
                "    [d, x2] = [x2, x1];\n",
                "\n",
                "    if (fx0 * fnew < 0) {\n",
                "      x1 = new_value;\n",
                "    } else {\n",
                "      x0 = new_value;\n",
                "    }\n",
                "\n",
                "    if (Math.abs(fx0) < Math.abs(fx1)) {\n",
                "      [x0, x1] = [x1, x0];\n",
                "    }\n",
                "\n",
                "    steps_taken += 1;\n",
                "  }\n",
                "  return x1;\n",
                "}\n",
                "\n",
                "// not used?\n",
                "function f(albedo, t1, t2, r0, ak1, ak2, ratm, r, toa_cor_o3) {\n",
                "  const surf = t1 * t2 * r0 * albedo ** (ak1 * ak2 / r0) / (1 - albedo * ratm);\n",
                "  const rs = r + surf\n",
                "  return toa_cor_o3 - rs;\n",
                "}\n",
                "\"\"\"\n",
                "\n",
                "logging.info(\"Configuration ok.\")    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "73747e53-868c-48ed-a19b-30833d656811",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'2021_07_09'"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "date_range = (f'{date}T8:00:00', f'{date}T18:00:00')\n",
                "\n",
                "DATE_FOLDER = date.replace(\"-\",\"_\")\n",
                "DL_FOLDER =  os.path.join('downloads', str(resolution), DATE_FOLDER)\n",
                "PROCESSED_FOLDER = f'{DL_FOLDER}/processed'\n",
                "\n",
                "DATE_FOLDER"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "7a5e0265-e157-4766-ab0b-3a27c810a7a8",
            "metadata": {},
            "outputs": [],
            "source": [
                "aoi_gpd = gpd.GeoDataFrame(geometry=[wkt.loads(aoi)], crs = \"EPSG:4326\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "5f538d34-ae35-4bf4-9dc7-3f076cca093e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-03-07 14:49:35 [INFO] root - Loading grid\n"
                    ]
                }
            ],
            "source": [
                "# load the 1 degree world grid from which the tiles will be calculated\n",
                "logging.info(\"Loading grid\")\n",
                "grid = gpd.read_file(os.environ[\"DATA_PATH\"] + \"/wgs84-1degree.geojson\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "4e04900a-036d-441b-887f-4dd8ab42528e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-03-07 14:49:39 [INFO] root - Calculating tiles to be processed.\n",
                        "/tmp/ipykernel_386/667727171.py:8: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
                        "\n",
                        "  toProcess = toProcess[toProcess.geometry.to_crs('epsg:4326').area > MIN_AREA]\n"
                    ]
                }
            ],
            "source": [
                "logging.info(\"Calculating tiles to be processed.\")    \n",
                "\n",
                "# make the intersection with the polygon so that we only calculate tiles inside the polygon\n",
                "toProcess=gpd.overlay(aoi_gpd, grid, how='intersection')\n",
                "\n",
                "#Remove chunks that are too small to be processed\n",
                "MIN_AREA = 1e-1\n",
                "toProcess = toProcess[toProcess.geometry.to_crs('epsg:4326').area > MIN_AREA]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "250fbc19-2ffc-4f2a-9de8-a1621cf08a5f",
            "metadata": {},
            "outputs": [],
            "source": [
                "# use full frames\n",
                "toProcess = grid[grid.ID.isin(list(toProcess.ID.values))]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "d072a099-71c3-40a2-9da8-6d74018dd727",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-03-07 14:49:46 [INFO] root - Folder downloads/1200/2021_07_09 deleted\n"
                    ]
                }
            ],
            "source": [
                "if DELETE_DOWNLOAD_FOLDER and os.path.exists(DL_FOLDER):\n",
                "    shutil.rmtree(DL_FOLDER)\n",
                "    logging.info(f'Folder {DL_FOLDER} deleted')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "f507df27-4ade-4858-b8ae-7bd3630d8508",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/88c8cc07-d79c-45b9-a407-ba18967711b0/.local/lib/python3.9/site-packages/sentinelhub/geometry.py:113: SHDeprecationWarning: Initializing `BBox` objects from `shapely` geometries will no longer be possible in future versions. Use the `bounds` property of the `shapely` geometry to initialize the `BBox` instead.\n",
                        "  x_fst, y_fst, x_snd, y_snd = BBox._to_tuple(bbox)\n"
                    ]
                }
            ],
            "source": [
                "listBbox = [BBox(bbox=geom, crs=\"EPSG:4326\") for geom in toProcess.geometry]\n",
                "listSizes = [bbox_to_dimensions(bbox, resolution=resolution) for bbox in listBbox]\n",
                "folderPaths = [f'{DL_FOLDER}/{round(id)}' for id in toProcess.ID]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "1f31486b-d9be-448a-b0f8-6cef32c0a741",
            "metadata": {},
            "outputs": [],
            "source": [
                "requests = [SentinelHubRequest(\n",
                "            evalscript=evalscript,\n",
                "            data_folder=folderPath,\n",
                "            input_data=[\n",
                "                SentinelHubRequest.input_data(\n",
                "                    data_collection=DataCollection.DEM_COPERNICUS_30,\n",
                "                    identifier=\"COP_30\",\n",
                "                    upsampling=\"NEAREST\",\n",
                "                    downsampling=\"NEAREST\",\n",
                "                ),\n",
                "                SentinelHubRequest.input_data(\n",
                "                    data_collection=DataCollection.SENTINEL3_OLCI,\n",
                "                    identifier=\"OLCI\",\n",
                "                    time_interval=date_range,\n",
                "                    upsampling=\"NEAREST\",\n",
                "                    downsampling=\"NEAREST\",\n",
                "                ),\n",
                "            ],\n",
                "            responses=[\n",
                "                SentinelHubRequest.output_response('r_TOA_01', MimeType.TIFF),\n",
                "                SentinelHubRequest.output_response('r_TOA_06', MimeType.TIFF),\n",
                "                SentinelHubRequest.output_response('r_TOA_17', MimeType.TIFF),\n",
                "                SentinelHubRequest.output_response('r_TOA_21', MimeType.TIFF),\n",
                "                SentinelHubRequest.output_response('snow_grain_diameter', MimeType.TIFF),\n",
                "                SentinelHubRequest.output_response('snow_specific_surface_area', MimeType.TIFF),\n",
                "                SentinelHubRequest.output_response('diagnostic_retrieval', MimeType.TIFF),\n",
                "                SentinelHubRequest.output_response('albedo_bb_planar_sw', MimeType.TIFF),\n",
                "                SentinelHubRequest.output_response('albedo_bb_spherical_sw', MimeType.TIFF),\n",
                "            ],\n",
                "            bbox=bb,\n",
                "            size=size,\n",
                "            config=sh_config\n",
                "        ) for bb, size, folderPath in zip(listBbox, listSizes, folderPaths)]\n",
                "\n",
                "#extract only downloader\n",
                "list_of_requests = [request.download_list[0] for request in requests]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "b94cb9ee-aee5-42d2-a3b0-478f09f02e3a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-03-07 14:49:46 [INFO] root - Starting download\n",
                        "2023-03-07 14:49:50 [INFO] root - Done\n"
                    ]
                }
            ],
            "source": [
                "logging.info('Starting download')\n",
                "downloader = SentinelHubDownloadClient(config=sh_config)\n",
                "downloader.download(list_of_requests, max_threads=20, show_progress=False)\n",
                "logging.info('Done')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "1f342f1e-7fb5-4d36-ae5f-14f9b1de414b",
            "metadata": {},
            "outputs": [],
            "source": [
                "def unzipFile(file, destination):\n",
                "    if not os.path.exists(os.path.join(destination, 'snow_grain_diameter.tif')):\n",
                "        tar = tarfile.open(file, \"r:\")\n",
                "        tar.extractall(path=destination)\n",
                "        tar.close()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "570022eb-619a-404c-ae0e-85a4061a3298",
            "metadata": {},
            "outputs": [],
            "source": [
                "class ConcurrentUnzipper:\n",
                "    def __init__(self, files, destinations):\n",
                "        self.files = files\n",
                "        self.destinations = destinations\n",
                "        \n",
                "    def operation(self, chunk):\n",
                "        unzipFile(self.files[chunk] , self.destinations[chunk])\n",
                "        \n",
                "    def unzipAll(self):\n",
                "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
                "            list(executor.map(self.operation, np.arange(0, len(self.files)), chunksize=1))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "ed28e0b8-b00f-4d6c-b1a9-9433a4d83d92",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-03-07 14:49:50 [INFO] root - Extracting .tar responses\n",
                        "2023-03-07 14:49:50 [INFO] root - Done\n"
                    ]
                }
            ],
            "source": [
                "filenamesList = glob.glob(f'./{DL_FOLDER}/*/*/response.tar')\n",
                "destinations =  [file.replace('response.tar', '') for file in filenamesList]        \n",
                "        \n",
                "logging.info('Extracting .tar responses')\n",
                "unzipper = ConcurrentUnzipper(filenamesList, destinations)\n",
                "unzipper.unzipAll()\n",
                "logging.info('Done')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "8523be7c-978a-4d4f-a96f-b57fe0810c62",
            "metadata": {},
            "outputs": [],
            "source": [
                "def mergeProduct(productName):\n",
                "    prodResult = productName.replace(\".tif\", '_merged.tif')\n",
                "    if os.path.exists(prodResult):\n",
                "        os.remove(prodResult)\n",
                "        logging.info(f'Deleted file: {prodResult}')\n",
                "    filenamesList = glob.glob(f'./{DL_FOLDER}/*/*/{productName}')\n",
                "    merge_tiffs(filenamesList, prodResult, overwrite=True)\n",
                "     \n",
                "class TifMerger:\n",
                "    def __init__(self, products):\n",
                "        self.products = products\n",
                "        \n",
                "    def operation(self, chunk):\n",
                "        mergeProduct(self.products[chunk])\n",
                "        \n",
                "    def process(self):\n",
                "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
                "            list(executor.map(self.operation, np.arange(0, len(self.products)), chunksize=1))    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "id": "3b8beba0-4f2b-4502-9e53-e8ebc66f01a7",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-03-07 14:49:50 [INFO] root - Merging products\n",
                        "2023-03-07 14:49:50 [INFO] root - merging 4 tiffs to albedo_bb_planar_sw_merged.tif\n",
                        "2023-03-07 14:49:50 [INFO] root - merging 4 tiffs to r_TOA_17_merged.tif\n",
                        "2023-03-07 14:49:50 [INFO] root - merging 4 tiffs to diagnostic_retrieval_merged.tif\n",
                        "2023-03-07 14:49:50 [INFO] root - merging 4 tiffs to r_TOA_06_merged.tif\n",
                        "2023-03-07 14:49:50 [INFO] root - merging 4 tiffs to albedo_bb_spherical_sw_merged.tif\n",
                        "2023-03-07 14:49:50 [INFO] root - merging 4 tiffs to snow_specific_surface_area_merged.tif\n",
                        "2023-03-07 14:49:50 [INFO] root - merging 4 tiffs to snow_grain_diameter_merged.tif\n",
                        "2023-03-07 14:49:50 [INFO] root - merging 4 tiffs to r_TOA_01_merged.tif\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "00000000"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-03-07 14:49:52 [INFO] root - merging done\n",
                        "2023-03-07 14:49:52 [INFO] root - merging 4 tiffs to r_TOA_21_merged.tif\n",
                        "2023-03-07 14:49:52 [INFO] root - merging done\n",
                        "2023-03-07 14:49:52 [INFO] root - merging done\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "...10...20.....10...20...30...40...50...60...70.....10...20.....10...20...30...40...50...10...20.....60...70.....10...20.....10...20...80...90...100 - done.\n",
                        "...10...20...30...40...50.30...40...50...60...70.....60...70...30...40...50...60...70...80...90...100 - done.\n",
                        ".30...40...50.30...40...50...60...70.....60...70...30...40...50...60...70...80...90...100 - done.\n",
                        ".80...90...100 - done.\n",
                        ".80...90...100 - done.\n",
                        ".80...90...100 - done.\n",
                        ".80...90...100 - done.\n",
                        ".80...90...100 - done.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-03-07 14:49:52 [INFO] root - merging done\n",
                        "2023-03-07 14:49:52 [INFO] root - merging done\n",
                        "2023-03-07 14:49:52 [INFO] root - merging done\n",
                        "2023-03-07 14:49:52 [INFO] root - merging done\n",
                        "2023-03-07 14:49:52 [INFO] root - merging done\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-03-07 14:49:52 [INFO] root - merging done\n",
                        "2023-03-07 14:49:52 [INFO] root - Done\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "...10...20...30...40...50...60...70...80...90...100 - done.\n"
                    ]
                }
            ],
            "source": [
                "#define the products that will be computed\n",
                "products = ['diagnostic_retrieval.tif','albedo_bb_planar_sw.tif','albedo_bb_spherical_sw.tif','snow_grain_diameter.tif', 'snow_specific_surface_area.tif', 'r_TOA_01.tif', 'r_TOA_06.tif', 'r_TOA_17.tif', 'r_TOA_21.tif']\n",
                "#products = ['snow_grain_diameter.tif']\n",
                "\n",
                "#merge individual tiles into one single image\n",
                "logging.info('Merging products')\n",
                "unzipper = TifMerger(products)\n",
                "unzipper.process()\n",
                "logging.info('Done')    \n",
                "\n",
                "resultsDataPath = os.path.join(USR_PATH, PROCESSED_FOLDER)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "20b0d472-d590-4605-878d-9ea7bc9f28f6",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'/home/88c8cc07-d79c-45b9-a407-ba18967711b0/downloads/1200/2021_07_09/processed'"
                        ]
                    },
                    "execution_count": 24,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "if not os.path.exists(PROCESSED_FOLDER):\n",
                "    os.makedirs(PROCESSED_FOLDER)\n",
                "    \n",
                "producedFiles = glob.glob('*_merged.tif')\n",
                "for prodResult in producedFiles:\n",
                "    shutil.move(prodResult, f'{PROCESSED_FOLDER}/{prodResult}')\n",
                "    \n",
                "resultsDataPath = os.path.join(USR_PATH, PROCESSED_FOLDER)\n",
                "resultsDataPath"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "id": "483ee047-9d65-481d-a3ca-7465f3d663ec",
            "metadata": {},
            "outputs": [],
            "source": [
                "processedDataPath = os.path.join(USR_PATH, PROCESSED_FOLDER)\n",
                "if len(projection) > 0 and not projection == '4326' : \n",
                "    destFolder = f'{DL_FOLDER}/warped/'\n",
                "\n",
                "    logging.info('Reprojecting to epsg:{projection}')\n",
                "    \n",
                "    if os.path.exists(destFolder):\n",
                "        shutil.rmtree(destFolder)\n",
                "\n",
                "    os.makedirs(destFolder)\n",
                "\n",
                "    for product in products:\n",
                "        srcFile = processedDataPath + \"/\" + product.replace(\".tif\", \"_merged.tif\")\n",
                "        destFile = f'{destFolder}/{product}'\n",
                "        cmd = f'gdalwarp {srcFile} {destFile}  -t_srs EPSG:{projection}'\n",
                "        os.system(cmd)\n",
                "   \n",
                "    resultsDataPath = destFolder\n",
                "else:\n",
                "    for product in products:\n",
                "        srcFile = processedDataPath + \"/\" + product.replace(\".tif\", \"_merged.tif\")\n",
                "        destFile = processedDataPath + \"/\" + product\n",
                "        if os.path.exists(srcFile):\n",
                "            os.rename(srcFile, destFile)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7a5764c4-dba7-4c6d-a401-ce094209beb8",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "bids2023-bids2023",
            "language": "python",
            "name": "conda-env-bids2023-bids2023-py"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.13"
        },
        "papermill": {
            "duration": 39.017723,
            "end_time": "2021-05-11T14:55:32.340726",
            "environment_variables": {},
            "exception": null,
            "input_path": "/tmp/tmpepv707p8",
            "output_path": "/tmp/cur_notebook.ipynb",
            "parameters": {},
            "start_time": "2021-05-11T14:54:53.323003",
            "version": "2.1.0"
        },
        "properties": {
            "description": "Operational Sentinel-3 snow and ice products (SICE)",
            "id": "sice",
            "name": "Operational Sentinel-3 snow and ice products (SICE)",
            "requirements": [
                "eurodatacube"
            ],
            "tags": [
                "Getting started",
                "Sentinel Hub"
            ],
            "version": "0.1"
        },
        "toc-autonumbering": true,
        "toc-showcode": true,
        "toc-showmarkdowntxt": true,
        "toc-showtags": true
    },
    "nbformat": 4,
    "nbformat_minor": 5
}